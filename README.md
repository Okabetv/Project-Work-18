# PW18 â€“ Triage automatico ticket di assistenza

Project Work â€“ Laurea Triennale in Informatica per le Aziende Digitali  
Traccia 18 â€“ Classificazione automatica ticket di assistenza

---

## Obiettivo del progetto

Il progetto sviluppa un **sistema di triage automatico** per i ticket di assistenza clienti che, partendo da un testo composto da **oggetto** e **descrizione**, Ã¨ capace di:

- classificare il ticket in una **categoria**:
  - Amministrazione
  - Tecnico
  - Commerciale
- stimare la **prioritÃ ** del ticket:
  - bassa
  - media
  - alta
- fornire una **spiegazione** utilizzando le parole o frasi piÃ¹ significative
- supportare **predizioni batch da CSV**
- visualizzare risultati e metriche attraverso una **dashboard web**

Il progetto si avvale di un **dataset sintetico**, creato appositamente, e **non include dati personali**.

---

## Struttura del progetto
```bash
PW 18/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # Dashboard Streamlit
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tickets.csv             # Dataset sintetico
â”‚   â”œâ”€â”€ predictions.csv         # Output batch
â”‚   â””â”€â”€ prediction_log.csv      # Log dashboard
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ category_model.joblib
â”‚   â””â”€â”€ priority_model.joblib
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ confusion_*.png
â”‚   â”œâ”€â”€ class_distribution_*.png
â”‚   â”œâ”€â”€ f1_per_class_*.png
â”‚   â”œâ”€â”€ metrics_summary.txt
â”‚   â””â”€â”€ metrics.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ explain.py              # SpiegabilitÃ  (top-words LogReg + NB)
â”‚   â”œâ”€â”€ features.py             # Preprocessing testo
â”‚   â”œâ”€â”€ generate_dataset.py     # Generazione dataset sintetico
â”‚   â”œâ”€â”€ predict_batch.py        # Predizione batch CSV
â”‚   â”œâ”€â”€ priority_hybrid.py      # PrioritÃ  ibrida (regole + ML)
â”‚   â””â”€â”€ report_figures.py       # Grafici per il report
â”‚   â”œâ”€â”€ train_models.py         # Training e valutazione modelli
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---

## Requisiti

- Python **3.10+**
- Sistema operativo: Windows / Linux / macOS

Librerie principali:
- pandas
- scikit-learn
- matplotlib
- joblib
- streamlit

---

## Installazione e dipendenze

Il progetto sfrutta un **ambiente virtuale Python** per assicurare isolamento e riproducibilitÃ .

## Creazione ambiente virtuale

```bash
python -m venv venv
```

## Attivazione ambiente

**Windows**

```bash
venv\Scripts\activate
```

**Linux / macOS**

```bash
source venv/bin/activate
```

## Installazione librerie

Tutte le dipendenze sono indicate nel file `requirements.txt`.

```bash
pip install -r requirements.txt
```

Il file `requirements.txt` include:

* `pandas` â€“ gestione dati e CSV
* `scikit-learn` â€“ modelli di Machine Learning
* `matplotlib` â€“ grafici e confusion matrix
* `joblib` â€“ salvataggio/caricamento modelli
* `streamlit` â€“ dashboard web interattiva

---

## Generazione dataset sintetico

Il dataset viene creato automaticamente con ticket che sembrano realistici.

```bash
python -m src.generate_dataset --n 350 --out data/tickets.csv
```

Colonne generate:

* `id`
* `title`
* `body`
* `category`
* `priority`

âœ”ï¸ Requisito traccia: **dataset sintetico 200â€“500 ticket**

---

## Training e valutazione modelli

```bash
python -m src.train_models > reports/metrics.txt
```

Durante il training:

* abbiamo diviso i dati in **80% per il training e 20% per il test**
* abbiamo confrontato **Logistic Regression e Naive Bayes** per la categoria
* abbiamo selezionato automaticamente il modello migliore basandoci sull'F1 macro
* abbiamo dato prioritÃ  al training del modello **Logistic Regression**

Metriche calcolate:

* Accuracy
* F1 macro
* F1 per classe
* Confusion Matrix

âœ”ï¸ Requisito traccia: **valutazione modelli**

---

## Grafici per il report

```bash
python -m src.report_figures
```

Grafici prodotti:

* Distribuzione classi (categoria e prioritÃ )
* F1-score per classe
* Confusion matrix

âœ”ï¸ Requisito traccia: **grafici e analisi risultati**

---

## Predizione batch da CSV

```bash
python -m src.predict_batch
```

Input:

* `data/tickets.csv` oppure CSV personalizzato con colonne `title`, `body`

Output:

* `data/predictions.csv` con:

  * categoria predetta
  * prioritÃ  predetta
  * probabilitÃ 
  * motivo prioritÃ  (regole / ML)

âœ”ï¸ Requisito traccia: **batch di ticket**

---

## Dashboard interattiva

```bash
streamlit run app/streamlit_app.py
```

FunzionalitÃ :

* Inserimento di un ticket singolo
* Classificazione per categoria e prioritÃ 
* PrioritÃ  **ibrida** (regole + machine learning)
* Visualizzazione delle **top-5 parole influenti**
* Upload di file CSV in batch
* Visualizzazione di metriche e grafici
* Log automatico delle predizioni

âœ”ï¸ Requisito traccia: **interfaccia grafica**

---

## PrioritÃ  ibrida

La prioritÃ  viene stimata attraverso un approccio **ibrido**:

1. Regole basate su parole chiave critiche (ad esempio *bloccante*, *crash*, *errore 500*)
2. Modello di machine learning per casi non critici
3. Fallback conservativo in caso di bassa confidenza

âœ”ï¸ Miglioramento realistico â€œda contesto aziendaleâ€

---

## SpiegabilitÃ  del modello

Per ogni predizione, vengono mostrate le **5 parole/frasi piÃ¹ influenti**, calcolate:

* per **Logistic Regression** tramite coefficienti
* per **Naive Bayes** tramite probabilitÃ  logaritmiche

âœ”ï¸ Requisito traccia: **interpretabilitÃ **

---

## ðŸ‘¤ Autore

Project Work realizzato da **Giancarlo Ierardi - Matr 0312300194**
Corso di Laurea in Informatica per le Aziende Digitali

---

## Reset del progetto (pulizia completa)

Questa sezione consente di **ripulire completamente il progetto**, rimuovendo file generati automaticamente come dataset, modelli e report. In questo modo, puoi **rigenerare tutto da zero** in modo riproducibile.

## File e cartelle generati automaticamente

I seguenti elementi **non fanno parte del codice sorgente** e vengono creati durante l'esecuzione:

* `data/*.csv` â†’ dataset e predizioni
* `models/*.joblib` â†’ modelli addestrati
* `reports/*.png` â†’ grafici e confusion matrix
* `reports/*.txt` â†’ metriche
* `data/prediction_log.csv` â†’ log dashboard
* `__pycache__/` â†’ cache Python

---

## Pulizia manuale (CMD â€“ Windows)

Eseguire i seguenti comandi **dalla root del progetto**.

## Eliminare dataset e output

```bash
del /Q data\*.csv
```

## Eliminare modelli addestrati

```bash
del /Q models\*.joblib
```

## Eliminare report e metriche

```bash
del /Q reports\*.png
del /Q reports\*.txt
```

### Eliminare log predizioni dashboard

```bash
del /Q data\prediction_log.csv
```

### Eliminare cache Python

```bash
rmdir /S /Q src\__pycache__
rmdir /S /Q app\__pycache__
```

---

## Reset completo (opzionale)

Per una pulizia totale, inclusa la rimozione dellâ€™ambiente virtuale:

```bash
rmdir /S /Q venv
```

Dopo questo comando sarÃ  necessario ricreare lâ€™ambiente virtuale e reinstallare le librerie.

---

## Rigenerazione completa da zero

Dopo la pulizia, per rigenerare lâ€™intero progetto:

```bash
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

python -m src.generate_dataset --n 350 --out data\tickets.csv
python -m src.train_models > reports\metrics.txt
python -m src.report_figures
python -m src.predict_batch
streamlit run app\streamlit_app.py
```

---
