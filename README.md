# PW18 â€“ Triage automatico ticket di assistenza

Project Work â€“ Laurea Triennale in Informatica per le Aziende Digitali  
Traccia 18 â€“ Classificazione automatica ticket di assistenza

---

## Obiettivo del progetto

Il progetto realizza un **sistema di triage automatico** per ticket di assistenza clienti che, dato un testo composto da **oggetto** e **descrizione**, Ã¨ in grado di:

- classificare il ticket in una **categoria**:
  - Amministrazione
  - Tecnico
  - Commerciale
- stimare la **prioritÃ ** del ticket:
  - bassa
  - media
  - alta
- fornire una **spiegazione** tramite le parole/frasi piÃ¹ influenti
- supportare **predizioni batch da CSV**
- visualizzare risultati e metriche tramite **dashboard web**

Il progetto utilizza **dataset sintetico**, generato ad hoc, e **non contiene dati personali**.

---

## Struttura del progetto
```bash
PW 18/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # Dashboard Streamlit
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tickets.csv             # Dataset sintetico
â”‚   â”œâ”€â”€ predictions.csv         # Output batch
â”‚   â””â”€â”€ prediction_log.csv      # Log dashboard
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ category_model.joblib
â”‚   â””â”€â”€ priority_model.joblib
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ confusion_*.png
â”‚   â”œâ”€â”€ class_distribution_*.png
â”‚   â”œâ”€â”€ f1_per_class_*.png
â”‚   â”œâ”€â”€ metrics_summary.txt
â”‚   â””â”€â”€ metrics.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ explain.py              # SpiegabilitÃ  (top-words LogReg + NB)
â”‚   â”œâ”€â”€ features.py             # Preprocessing testo
â”‚   â”œâ”€â”€ generate_dataset.py     # Generazione dataset sintetico
â”‚   â”œâ”€â”€ predict_batch.py        # Predizione batch CSV
â”‚   â”œâ”€â”€ priority_hybrid.py      # PrioritÃ  ibrida (regole + ML)
â”‚   â””â”€â”€ report_figures.py       # Grafici per il report
â”‚   â”œâ”€â”€ train_models.py         # Training e valutazione modelli
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---

## Requisiti

- Python **3.10+**
- Sistema operativo: Windows / Linux / macOS

Librerie principali:
- pandas
- scikit-learn
- matplotlib
- joblib
- streamlit

---

## Installazione e dipendenze

Il progetto utilizza un **ambiente virtuale Python** per garantire isolamento e riproducibilitÃ .

## Creazione ambiente virtuale

```bash
python -m venv venv
```

## Attivazione ambiente

**Windows**

```bash
venv\Scripts\activate
```

**Linux / macOS**

```bash
source venv/bin/activate
```

## Installazione librerie

Tutte le dipendenze sono elencate nel file `requirements.txt`.

```bash
pip install -r requirements.txt
```

Il file `requirements.txt` include:

* `pandas` â€“ gestione dati e CSV
* `scikit-learn` â€“ modelli di Machine Learning
* `matplotlib` â€“ grafici e confusion matrix
* `joblib` â€“ salvataggio/caricamento modelli
* `streamlit` â€“ dashboard web interattiva

---

## Generazione dataset sintetico

Il dataset viene generato automaticamente con ticket realistici.

```bash
python -m src.generate_dataset --n 350 --out data/tickets.csv
```

Colonne generate:

* `id`
* `title`
* `body`
* `category`
* `priority`

âœ”ï¸ Requisito traccia: **dataset sintetico 200â€“500 ticket**

---

## Training e valutazione modelli

```bash
python -m src.train_models > reports/metrics.txt
```

Durante il training:

* split **80% training / 20% test**
* confronto **Logistic Regression vs Naive Bayes** per la categoria
* selezione automatica del modello migliore (F1 macro)
* training modello prioritÃ  (Logistic Regression)

Metriche calcolate:

* Accuracy
* F1 macro
* F1 per classe
* Confusion Matrix

âœ”ï¸ Requisito traccia: **valutazione modelli**

---

## Grafici per il report

```bash
python -m src.report_figures
```

Grafici prodotti:

* Distribuzione classi (categoria e prioritÃ )
* F1-score per classe
* Confusion matrix

âœ”ï¸ Requisito traccia: **grafici e analisi risultati**

---

## Predizione batch da CSV

```bash
python -m src.predict_batch
```

Input:

* `data/tickets.csv` oppure CSV personalizzato con colonne `title`, `body`

Output:

* `data/predictions.csv` con:

  * categoria predetta
  * prioritÃ  predetta
  * probabilitÃ 
  * motivo prioritÃ  (regole / ML)

âœ”ï¸ Requisito traccia: **batch di ticket**

---

## Dashboard interattiva

```bash
streamlit run app/streamlit_app.py
```

FunzionalitÃ :

* Inserimento ticket singolo
* Classificazione categoria e prioritÃ 
* PrioritÃ  **ibrida** (regole + ML)
* Visualizzazione **top-5 parole influenti**
* Upload CSV batch
* Visualizzazione metriche e grafici
* Log automatico delle predizioni

âœ”ï¸ Requisito traccia: **interfaccia grafica**

---

## PrioritÃ  ibrida

La prioritÃ  Ã¨ stimata con approccio **ibrido**:

1. Regole basate su keyword critiche (es. *bloccante*, *crash*, *errore 500*)
2. Modello ML per casi non critici
3. Fallback conservativo in caso di bassa confidenza

âœ”ï¸ Miglioramento realistico â€œda contesto aziendaleâ€

---

## SpiegabilitÃ  del modello

Per ogni predizione vengono mostrate le **5 parole/frasi piÃ¹ influenti**, calcolate:

* per **Logistic Regression** tramite coefficienti
* per **Naive Bayes** tramite probabilitÃ  logaritmiche

âœ”ï¸ Requisito traccia: **interpretabilitÃ **

---

## Allineamento con la Traccia 18

| Requisito traccia          | Stato |
| -------------------------- | ----- |
| Dataset sintetico 200â€“500  | âœ…    |
| Classificazione categoria  | âœ…    |
| Stima prioritÃ              | âœ…    |
| Preprocessing testo        | âœ…    |
| Modelli ML                 | âœ…    |
| Valutazione (Accuracy, F1) | âœ…    |
| Confusion Matrix           | âœ…    |
| Batch CSV                  | âœ…    |
| Dashboard grafica          | âœ…    |
| SpiegabilitÃ                | âœ…    |

## ðŸ‘¤ Autore

Project Work realizzato da **Giancarlo Ierardi - Matr 0312300194**
Corso di Laurea in Informatica per le Aziende Digitali

---

## Reset del progetto (pulizia completa)

Questa sezione permette di **ripulire completamente il progetto** eliminando file generati automaticamente (dataset, modelli, report), cosÃ¬ da poter **rigenerare tutto da zero** in modo riproducibile.

## File e cartelle generati automaticamente

I seguenti elementi **non fanno parte del codice sorgente** e vengono creati durante lâ€™esecuzione:

* `data/*.csv` â†’ dataset e predizioni
* `models/*.joblib` â†’ modelli addestrati
* `reports/*.png` â†’ grafici e confusion matrix
* `reports/*.txt` â†’ metriche
* `data/prediction_log.csv` â†’ log dashboard
* `__pycache__/` â†’ cache Python

---

## Pulizia manuale (CMD â€“ Windows)

Eseguire i seguenti comandi **dalla root del progetto**.

## Eliminare dataset e output

```bash
del /Q data\*.csv
```

## Eliminare modelli addestrati

```bash
del /Q models\*.joblib
```

## Eliminare report e metriche

```bash
del /Q reports\*.png
del /Q reports\*.txt
```

### Eliminare log predizioni dashboard

```bash
del /Q data\prediction_log.csv
```

### Eliminare cache Python

```bash
rmdir /S /Q src\__pycache__
rmdir /S /Q app\__pycache__
```

---

## Reset completo (opzionale)

Per una pulizia totale, inclusa la rimozione dellâ€™ambiente virtuale:

```bash
rmdir /S /Q venv
```

Dopo questo comando sarÃ  necessario ricreare lâ€™ambiente virtuale e reinstallare le librerie.

---

## Rigenerazione completa da zero

Dopo la pulizia, per rigenerare lâ€™intero progetto:

```bash
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

python -m src.generate_dataset --n 350 --out data\tickets.csv
python -m src.train_models > reports\metrics.txt
python -m src.report_figures
python -m src.predict_batch
streamlit run app\streamlit_app.py
```

---
